{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\harshit\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist(images_path: str, labels_path: str):\n",
    "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
    "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path,'rb') as imagesFile:\n",
    "        length = len(labels)\n",
    "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
    "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
    "                        .reshape(length, 784) \\\n",
    "                        .reshape(length, 28, 28, 1)\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "\n",
    "train['features'], train['labels'] = read_mnist('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
    "test['features'], test['labels'] = read_mnist('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 60000\n",
      "# of test images: 10000\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of test images:', test['features'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(position):\n",
    "    image = train['features'][position].squeeze()\n",
    "    plt.title('Example %d. Label: %d' % (position, train['labels'][position]))\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Count\n",
       "0      0   5923\n",
       "1      1   6742\n",
       "2      2   5958\n",
       "3      3   6131\n",
       "4      4   5842\n",
       "5      5   5421\n",
       "6      6   5918\n",
       "7      7   6265\n",
       "8      8   5851\n",
       "9      9   5949"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_count = np.unique(train['labels'], return_counts=True)\n",
    "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
    "dataframe_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.catplot(x=\"Label\", y=\"Count\",\n",
    "#             kind=\"bar\",\n",
    "#             data=dataframe_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['features'], train['labels'] = shuffle(train['features'], train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {}\n",
    "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 48000\n",
      "# of validation images: 12000\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of validation images:', validation['features'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10  #10\n",
    "BATCH_SIZE = 12   #120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.contrib.layers import flatten\n",
    "from tensorflow.compat.v1.layers import flatten\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1    \n",
    "    \n",
    "    weights = {\n",
    "        # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "        'conv1': tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma)),\n",
    "        'conv2': tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "        'fl1': tf.Variable(tf.truncated_normal(shape=(5 * 5 * 16, 120), mean = mu, stddev = sigma)),\n",
    "        'fl2': tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma)),\n",
    "        'out': tf.Variable(tf.truncated_normal(shape=(84, n_classes), mean = mu, stddev = sigma))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        # The shape of the filter bias is (output_depth,)\n",
    "        'conv1': tf.Variable(tf.zeros(6)),\n",
    "        'conv2': tf.Variable(tf.zeros(16)),\n",
    "        'fl1': tf.Variable(tf.zeros(120)),\n",
    "        'fl2': tf.Variable(tf.zeros(84)),\n",
    "        'out': tf.Variable(tf.zeros(n_classes))\n",
    "    }\n",
    "\n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1 = tf.nn.conv2d(x, weights['conv1'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, biases['conv1'])\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.avg_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2 = tf.nn.conv2d(conv1, weights['conv2'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, biases['conv2'])\n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.avg_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    fl0 = flatten(conv2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fl1 = tf.add(tf.matmul(fl0, weights['fl1']), biases['fl1'])\n",
    "    # Activation.\n",
    "    fl1 = tf.nn.relu(fl1)\n",
    "    \n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fl2 = tf.add(tf.matmul(fl1, weights['fl2']), biases['fl2'])\n",
    "    # Activation.\n",
    "    fl2 = tf.nn.relu(fl2)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    logits = tf.add(tf.matmul(fl2, weights['out']), biases['out'])\n",
    "                 \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-58-d31d8e36b6a8>:46: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\harshit\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-60-e4369957516b>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        \n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LeNet...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.977\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.976\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    num_examples = len(train['features'])\n",
    "    \n",
    "    print(\"Training LeNet...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(train['features'], train['labels'])\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            session.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(validation['features'], validation['labels'])\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    train_file_writer = tf.summary.FileWriter('logs', session.graph)\n",
    "    train_file_writer.close()\n",
    "    \n",
    "    saver.save(session, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.985\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(test['features'], test['labels'])\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
